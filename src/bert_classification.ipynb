{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Initial setup (Main Libraries Download and Torch setting)"
      ],
      "metadata": {
        "id": "KWug3pp7gdQX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!curl ipinfo.io"
      ],
      "metadata": {
        "id": "woRAitLHUA7b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eX2cBhFBmt_v"
      },
      "outputs": [],
      "source": [
        "# Install huggingface library\n",
        "!pip install torch ray==2.6.3 transformers hyperopt accelerate evaluate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1Z_gfa3yHcTZ"
      },
      "outputs": [],
      "source": [
        "!pip install codecarbon"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OtAGfUBfmS6v"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "# Torch GPU setting\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3_NBCFSnq8YK"
      },
      "outputs": [],
      "source": [
        "#Google Drive Source setup\n",
        "\n",
        "%cd /content\n",
        "!mkdir gdrive\n",
        "%cd gdrive\n",
        "!mkdir \"My Drive\"\n",
        "!google-drive-ocamlfuse \"/content/gdrive/My Drive\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AmLbsauSnNQl"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "\n",
        "# Google Drive Disk Mount\n",
        "\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5_XwMwHXrwpW"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import numpy as np\n",
        "\n",
        "# Set the seed value all over the place to make this reproducible.\n",
        "seed_val = 42\n",
        "\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataset Loading and Preprocessing"
      ],
      "metadata": {
        "id": "oJfuMmWYcgMj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "05EYObSwnqRA"
      },
      "outputs": [],
      "source": [
        "# read here your dataset\n",
        "import pandas as pd\n",
        "\n",
        "columns_to_read = [\"text\", \"isgreen\"] # Task #1\n",
        "#columns_to_read = [\"text\", \"sentiment\"] # Task #2\n",
        "\n",
        "train = pd.read_csv(\"/content/gdrive/My Drive/dataset_exp/original/trainset.tsv\", delimiter='\\t', usecols=columns_to_read).dropna()\n",
        "train['isgreen'] = train['isgreen'].replace({'Eco-related': 1, 'Not eco-related': 0})\n",
        "#train['sentiment'] = train['sentiment'].replace({'Positive': 1, 'Negative': 0, 'Neutral': 2})\n",
        "train.rename(columns={'text': 'sentence'}, inplace=True)\n",
        "train.rename(columns={'isgreen': 'label'}, inplace=True)\n",
        "#train.rename(columns={'sentiment': 'label'}, inplace=True)\n",
        "\n",
        "eval = pd.read_csv(\"/content/gdrive/My Drive/dataset_exp/original/testset.tsv\", delimiter='\\t', usecols=columns_to_read).dropna()\n",
        "eval['isgreen'] = eval['isgreen'].replace({'Eco-related': 1, 'Not eco-related': 0})\n",
        "#eval['sentiment'] = eval['sentiment'].replace({'Positive': 1, 'Negative': 0, 'Neutral': 2})\n",
        "eval.rename(columns={'text': 'sentence'}, inplace=True)\n",
        "eval.rename(columns={'isgreen': 'label'}, inplace=True)\n",
        "#eval.rename(columns={'sentiment': 'label'}, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7bl9NcAVn1nx"
      },
      "outputs": [],
      "source": [
        "train.head()\n",
        "eval.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g6eXsepVn6I6"
      },
      "outputs": [],
      "source": [
        "# get here your sentences and labels\n",
        "train_sentences = train.sentence.values\n",
        "train_labels = train.label.values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iAnWo7FVn-RK"
      },
      "outputs": [],
      "source": [
        "# get here your sentences and labels\n",
        "eval_sentences = eval.sentence.values\n",
        "eval_labels = eval.label.values"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model setup and Training"
      ],
      "metadata": {
        "id": "gZX5uIH1ctve"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "63_c4eF3oCPq"
      },
      "outputs": [],
      "source": [
        "# BERT tokenizer: To feed our text to BERT, it must be split into tokens, and then these tokens must be mapped to their index in the tokenizer vocabulary\n",
        "from transformers import AutoTokenizer\n",
        "\n",
        "huggingface_model_name = 'bert-base-cased'\n",
        "#uggingface_model_name = 'roberta-base'\n",
        "#huggingface_model_name = 'distilroberta-base'\n",
        "#huggingface_model_name = 'climatebert/distilroberta-base-climate-f'\n",
        "#huggingface_model_name = 'climatebert/distilroberta-base-climate-s'\n",
        "\n",
        "# Load the BERT tokenizer\n",
        "print('Loading tokenizer...')\n",
        "tokenizer = AutoTokenizer.from_pretrained(huggingface_model_name, do_lower_case=True)  # it will download and save it in a cache local directory"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preparing Data for Classification with BERT: Tokenization, Padding, and Attention Mask Generation"
      ],
      "metadata": {
        "id": "48uvf1pwdzqO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ikGxnYBmoxyq"
      },
      "outputs": [],
      "source": [
        "max_length = 128\n",
        "num_labels = 2\n",
        "#num_labels = 3 # Task #3\n",
        "\n",
        "input_ids = []\n",
        "attention_masks = []\n",
        "train_lab_tensor = torch.zeros((len(train_sentences), num_labels))\n",
        "\n",
        "for i, sent in enumerate(train_sentences):\n",
        "    # `encode_plus` will:\n",
        "    #   (1) Tokenize the sentence.\n",
        "    #   (2) Prepend the `[CLS]` token to the start.\n",
        "    #   (3) Append the `[SEP]` token to the end.\n",
        "    #   (4) Map tokens to their IDs.\n",
        "    #   (5) Pad or truncate the sentence to `max_length`\n",
        "    #   (6) Create attention masks for [PAD] tokens.\n",
        "    encoded_dict = tokenizer(\n",
        "                        sent,                      # Sentence to encode.\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                        max_length = max_length,           # Pad & truncate all sentences.\n",
        "                        padding='max_length',\n",
        "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                        truncation=True,\n",
        "                   )\n",
        "\n",
        "    # Add the encoded sentence to the list.\n",
        "    input_ids.append(encoded_dict['input_ids'])\n",
        "\n",
        "    # And its attention mask (simply differentiates padding from non-padding).\n",
        "    attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "    # add label to lab_tensor\n",
        "    if train_labels[i] <= float(num_labels):\n",
        "      train_lab_tensor[i, int(train_labels[i])] = 1\n",
        "\n",
        "# Convert the lists into tensors.\n",
        "train_input_ids = torch.cat(input_ids, dim=0)\n",
        "train_attention_masks = torch.cat(attention_masks, dim=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fWxzpnOGS8R1"
      },
      "outputs": [],
      "source": [
        "# let's encode the evaluation dataset\n",
        "\n",
        "max_length = 128 # instead of 47, just in case there are some longer test sentences\n",
        "num_labels = 2\n",
        "\n",
        "input_ids = []\n",
        "attention_masks = []\n",
        "eval_lab_tensor = torch.zeros((len(eval_sentences), num_labels))\n",
        "\n",
        "# For every sentence...\n",
        "for i, sent in enumerate(eval_sentences):\n",
        "    # `encode_plus` will:\n",
        "    #   (1) Tokenize the sentence.\n",
        "    #   (2) Prepend the `[CLS]` token to the start.\n",
        "    #   (3) Append the `[SEP]` token to the end.\n",
        "    #   (4) Map tokens to their IDs.\n",
        "    #   (5) Pad or truncate the sentence to `max_length`\n",
        "    #   (6) Create attention masks for [PAD] tokens.\n",
        "    encoded_dict = tokenizer(\n",
        "                        sent,                      # Sentence to encode.\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                        max_length = max_length,           # Pad & truncate all sentences.\n",
        "                        padding='max_length',\n",
        "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                        truncation=True,\n",
        "                   )\n",
        "\n",
        "    # Add the encoded sentence to the list.\n",
        "    input_ids.append(encoded_dict['input_ids'])\n",
        "\n",
        "    # And its attention mask (simply differentiates padding from non-padding).\n",
        "    attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "    # add label to lab_tensor\n",
        "    if eval_labels[i] <= float(num_labels):\n",
        "      eval_lab_tensor[i, int(eval_labels[i])] = 1\n",
        "\n",
        "# Convert the lists into tensors.\n",
        "eval_input_ids = torch.cat(input_ids, dim=0)\n",
        "eval_attention_masks = torch.cat(attention_masks, dim=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Custom Iterable DataLoader Definition"
      ],
      "metadata": {
        "id": "SDoAGgJTeKJ3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VOrj09kGXlgT"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import IterableDataset\n",
        "from torch.utils.data import TensorDataset, random_split\n",
        "\n",
        "\n",
        "class MyDataLoader(IterableDataset):\n",
        "\n",
        "  def __init__(self, ids, mask, labels):\n",
        "    super(MyDataLoader).__init__()\n",
        "    self._ids = ids\n",
        "    self._mask = mask\n",
        "    self._labels = labels\n",
        "\n",
        "  def __len__(self):\n",
        "    return self._ids.size(dim=0)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    item = dict()\n",
        "    item[\"input_ids\"] = torch.Tensor(self._ids[idx])\n",
        "    item[\"attention_mask\"] = torch.Tensor(self._mask[idx])\n",
        "    item[\"labels\"] = self._labels[idx, :]\n",
        "    return item"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nX0t03OopEwn"
      },
      "outputs": [],
      "source": [
        "# training and validation split - 90% train and 10% valid\n",
        "from torch.utils.data import TensorDataset, random_split\n",
        "\n",
        "# Combine the training inputs into a TensorDataset.\n",
        "trainset = MyDataLoader(train_input_ids, train_attention_masks, train_lab_tensor)\n",
        "evalset = MyDataLoader(eval_input_ids, eval_attention_masks, eval_lab_tensor)\n",
        "\n",
        "trainset, _ = random_split(trainset, [len(trainset), 0])\n",
        "evalset, _ = random_split(evalset,  [len(evalset), 0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O9A35XtKpsaR"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "# The DataLoader needs to know our batch size for training, so we specify it\n",
        "# here. For fine-tuning BERT on a specific task, the authors recommend a batch\n",
        "# size of 16 or 32.\n",
        "batch_size = 32\n",
        "\n",
        "# Create the DataLoaders for our training and validation sets.\n",
        "# We'll take training samples in random order.\n",
        "\n",
        "train_dataloader = DataLoader(\n",
        "            trainset,  # The training samples.\n",
        "            sampler=RandomSampler(trainset),\n",
        "            batch_size = batch_size # Train with this batch size.\n",
        "        )\n",
        "\n",
        "# For validation the order doesn't matter, so we'll just read them sequentially.\n",
        "validation_dataloader = DataLoader(\n",
        "            evalset, # The validation samples.\n",
        "            sampler=SequentialSampler(evalset),\n",
        "            batch_size = batch_size # Evaluate with this batch size.\n",
        "        )"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## AutoModel loading and Metrics definition"
      ],
      "metadata": {
        "id": "niWmwdp7el1o"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kV4IOx2Yp0Kx"
      },
      "outputs": [],
      "source": [
        "# define the model - we will use BERTForSequenceClassification because it has the same BERT architecture but with a single classification layer on top\n",
        "from transformers import AutoModelForSequenceClassification\n",
        "\n",
        "# Load BertForSequenceClassification, the pretrained BERT model with a single\n",
        "# linear classification layer on top.\n",
        "\n",
        "def my_model_init():\n",
        "  model = AutoModelForSequenceClassification.from_pretrained(        # use DistilBertForSequenceClassification if you want\n",
        "      huggingface_model_name,\n",
        "      num_labels = 2, # The number of output labels--2 for binary classification.\n",
        "                      # You can increase this for multi-class tasks.\n",
        "      output_attentions = False, # Whether the model returns attentions weights.\n",
        "      output_hidden_states = False, # Whether the model returns all hidden-states.\n",
        "      return_dict=True\n",
        "  )\n",
        "\n",
        "  for name, param in model.named_parameters():\n",
        "    if 'Bert' in name:\n",
        "      param.requires_grad = False\n",
        "\n",
        "  model.to(device)\n",
        "\n",
        "  return model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j4P3XduDQbfF"
      },
      "outputs": [],
      "source": [
        "from transformers import EvalPrediction\n",
        "from sklearn.metrics import f1_score, precision_score, recall_score, roc_auc_score, accuracy_score\n",
        "\n",
        "\n",
        "def compute_metrics(p: EvalPrediction):\n",
        "  y_true = p.label_ids\n",
        "  preds = p.predictions[0] if isinstance(p.predictions, tuple) else p.predictions\n",
        "  #y_pred = torch.zeros(preds.shape)\n",
        "  #args = torch.argmax(torch.Tensor(preds), dim=1)\n",
        "  #y_pred[:,args[:]] = 1\n",
        "\n",
        "  y_pred = preds.argmax(-1)\n",
        "  y_true = y_true.argmax(-1)\n",
        "\n",
        "\n",
        "  new_df = pd.DataFrame( )\n",
        "  new_df['pred_label'] = y_pred\n",
        "  new_df['true_label'] = y_true\n",
        "  new_df.to_csv(f'/content/gdrive/My Drive/eco_project_model/{huggingface_model_name}/noclimatescam/predictions.csv', header=True)\n",
        "\n",
        "  #precision = precision_score(y_true=y_true, y_pred=y_pred, average='weighted')\n",
        "  #recall = recall_score(y_true=y_true, y_pred=y_pred, average='weighted')\n",
        "  #f1_micro_average = f1_score(y_true=y_true, y_pred=y_pred, average='weighted')\n",
        "  #roc_auc = roc_auc_score(y_true, y_pred, average='weighted')\n",
        "\n",
        "  precision = precision_score(y_true=y_true, y_pred=y_pred, average='macro')\n",
        "  recall = recall_score(y_true=y_true, y_pred=y_pred, average='macro')\n",
        "  f1_micro_average = f1_score(y_true=y_true, y_pred=y_pred, average='macro')\n",
        "  #roc_auc = roc_auc_score(y_true, y_pred, average='micro', multi_class='ovo')\n",
        "\n",
        "  accuracy = accuracy_score(y_true, y_pred)\n",
        "  #metrics = {'p': precision,\n",
        "  #           'r': recall,\n",
        "  #           'f1': f1_micro_average,\n",
        "  #           'roc_auc': roc_auc,\n",
        "  #           'accuracy': accuracy}\n",
        "  metrics = {'p': precision,\n",
        "            'r': recall,\n",
        "            'f1': f1_micro_average,\n",
        "            #'roc_auc': roc_auc,\n",
        "            'accuracy': accuracy}\n",
        "  return metrics\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Hyperparameters setting"
      ],
      "metadata": {
        "id": "X8TbPvJVe6Zi"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u54hLk74Qr_K"
      },
      "outputs": [],
      "source": [
        "batch_size = 16\n",
        "num_epochs = 10\n",
        "\n",
        "lr = 3e-5\n",
        "eps= 2e-10\n",
        "adam_beta_1 = 0.9\n",
        "adam_beta_2 = 0.999\n",
        "warmup_steps = len(trainset) * num_epochs\n",
        "\n",
        "out_dir = f'/content/gdrive/My Drive/eco_project_model/{huggingface_model_name}/original'\n",
        "num_saved_models = 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TDRuympcRZpl"
      },
      "outputs": [],
      "source": [
        "from transformers import Trainer, TrainingArguments\n",
        "\n",
        "training_args = TrainingArguments(output_dir=out_dir,\n",
        "                                  overwrite_output_dir=True,\n",
        "                                  do_train=True,\n",
        "                                  do_eval=True,\n",
        "                                  #do_test=True,\n",
        "                                  do_predict=True,\n",
        "                                  fp16=True,\n",
        "                                  evaluation_strategy='epoch',\n",
        "                                  per_device_train_batch_size=batch_size,\n",
        "                                  per_device_eval_batch_size=batch_size,\n",
        "                                  learning_rate=lr,\n",
        "                                  #adam_beta1=adam_beta_1,\n",
        "                                  #adam_beta2=adam_beta_2,\n",
        "                                  adam_epsilon=eps,\n",
        "                                  lr_scheduler_type='linear',\n",
        "                                  warmup_steps=warmup_steps,\n",
        "                                  num_train_epochs=num_epochs,\n",
        "                                  save_strategy='epoch',\n",
        "                                  save_total_limit=num_saved_models,\n",
        "                                  load_best_model_at_end=True,\n",
        "                                  metric_for_best_model='p',\n",
        "                                  logging_strategy='epoch')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gPxKwDJTYuGI"
      },
      "outputs": [],
      "source": [
        "trainer = Trainer(\n",
        "    model_init=my_model_init,\n",
        "    args=training_args,\n",
        "    train_dataset=trainset,\n",
        "    eval_dataset=evalset,\n",
        "    compute_metrics=compute_metrics\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Actual Training (with Emissions Tracker)"
      ],
      "metadata": {
        "id": "fWIwOWNUfMAk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "npH2uSbtSJ0B"
      },
      "outputs": [],
      "source": [
        "#from codecarbon import EmissionsTracker\n",
        "\n",
        "\n",
        "#tracker = EmissionsTracker()\n",
        "#tracker.start()\n",
        "trainer.train()\n",
        "#emissions: float = tracker.stop()\n",
        "#print(emissions)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Evaluation"
      ],
      "metadata": {
        "id": "EoQIgUfvfTQo"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WYLcewf-SLaz"
      },
      "outputs": [],
      "source": [
        "trainer.evaluate()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Ray Optimal Hyperparameter search"
      ],
      "metadata": {
        "id": "qsJXZQ2Cfaq2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a8oR-CJ7QqRk"
      },
      "outputs": [],
      "source": [
        "from contextlib import suppress\n",
        "from ray import tune\n",
        "from ray.air.config import CheckpointConfig\n",
        "from ray.tune import CLIReporter\n",
        "from ray.tune.examples.pbt_transformers.utils import (\n",
        "    download_data,\n",
        "    build_compute_metrics_fn,\n",
        ")\n",
        "from ray.tune.schedulers import PopulationBasedTraining"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WvG9gDfGQuG2"
      },
      "outputs": [],
      "source": [
        "tune_config = {\n",
        "    \"per_device_train_batch_size\": batch_size,\n",
        "    \"per_device_eval_batch_size\": batch_size,\n",
        "    \"num_train_epochs\": tune.choice([2, 3, 5, 10, 15, 20, 25, 30]),\n",
        "    \"max_steps\": -1\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ih-7XpEJRDYl"
      },
      "outputs": [],
      "source": [
        "scheduler = PopulationBasedTraining(\n",
        "    time_attr=\"training_iteration\",\n",
        "    metric=\"eval_f1\",\n",
        "    mode=\"max\",\n",
        "    perturbation_interval=1,\n",
        "    hyperparam_mutations={\n",
        "        \"weight_decay\": tune.uniform(0.0, 0.5),\n",
        "        \"learning_rate\": tune.uniform(1e-5, 5e-5),\n",
        "        \"per_device_train_batch_size\": [8, 16, 32, 64],\n",
        "        \"adam_epsilon\": tune.uniform(1e-10, 1e-8),\n",
        "        \"warmup_steps\": tune.randint(len(trainset), warmup_steps)\n",
        "    },\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nWSmC9rARM3Z"
      },
      "outputs": [],
      "source": [
        "reporter = CLIReporter(\n",
        "    parameter_columns={\n",
        "        \"weight_decay\": \"w_decay\",\n",
        "        \"learning_rate\": \"lr\",\n",
        "        \"per_device_train_batch_size\": \"train_bs/gpu\",\n",
        "        \"num_train_epochs\": \"num_epochs\",\n",
        "    },\n",
        "    metric_columns=[\"eval_f1\", \"eval_loss\", \"epoch\", \"training_iteration\"],\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z45YszJCRnJ-"
      },
      "outputs": [],
      "source": [
        "best_res = trainer.hyperparameter_search(\n",
        "        hp_space=lambda _: tune_config,\n",
        "        backend=\"ray\",\n",
        "        resources_per_trial={\"cpu\": 1, \"gpu\": 1},\n",
        "        scheduler=scheduler,\n",
        "        checkpoint_config=CheckpointConfig(\n",
        "            num_to_keep=1,\n",
        "            checkpoint_score_attribute=\"training_iteration\",\n",
        "        ),\n",
        "        stop=None,\n",
        "        progress_reporter=reporter,\n",
        "        local_dir=\"~/ray_results/\",\n",
        "        name=\"tune_transformer_pbt\",\n",
        "        log_to_file=True,\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WRr7Erq66fE1"
      },
      "outputs": [],
      "source": [
        "print(best_res)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}